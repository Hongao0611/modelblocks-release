[data]
series_ids = subject docid
split_ids = subject sentid
modulus = 4

[dtsr_settings]
network_type = bayes
inference_name = KLqp
conv_prior_sd = 1
init_sd = .01
prior_sd_scaling_coefficient = 1
y_scale_prior_sd_scaling_coefficient = 1
ranef_to_fixef_prior_sd_ratio = 1
posterior_to_prior_sd_ratio = 0.01
declare_priors_fixef = False
declare_priors_ranef = False
ranef_regularizer_name = l2_regularizer
ranef_regularizer_scale = 1.

n_iter = 5000
optim = Nadam
learning_rate = .001
ema_decay = 0.999
minibatch_size = 1024
eval_minibatch_size = 100000

n_samples = 2
n_samples_eval = 256

log_freq = 10
save_freq = 100
plot_x_inches = 6
plot_y_inches = 4

[irf_name_map]
DiracDelta.s(trial)-Terminal.s(trial) = Trial
DiracDelta.s(log(trial))-Terminal.s(log(trial)) = Trial
DiracDelta.s(sentpos)-Terminal.s(sentpos) = Sentence position
ShiftedGammaShapeGT1.rate-Terminal.rate = Rate
ShiftedGammaShapeGT1.prevwasfix-Terminal.prevwasfix = Previous fixated
ShiftedGammaShapeGT1.s(wdelta)-Terminal.s(wdelta) = Saccade length
ShiftedGammaShapeGT1.s(wlen)-Terminal.s(wlen) = Word length
ShiftedGammaShapeGT1.s(unigram)-Terminal.s(unigram) = Unigram logprob
ShiftedGammaShapeGT1.s(fwprob5surp)-Terminal.s(fwprob5surp) = 5-gram surprisal

[filters]
fdurGP = > 0
wdelta = <= 4
startofsentence = != 1
endofsentence = != 1
startofline = != 1
endofline = != 1
startofscreen = != 1
endofscreen = != 1
startoffile = != 1
endoffile = != 1

[impulse_to_irf]
default = ShiftedGammaShapeGT1(alpha=2, beta=5, delta=-0.2, ran=T)

[model_DTSR_template]
formula = log(fdurGP) ~ C(s.(trial) + s.(sentpos), DiracDelta()) + C(rate + prevwasfix + s.(wdelta) + s.(wlen) + s.(unigram) + s.(fwprob5surp), ShiftedGammaShapeGT1(alpha=2, beta=5, delta=-0.2)) + (C(s.(trial) + s.(sentpos), DiracDelta()) + C(rate + prevwasfix + s.(wdelta) + s.(wlen) + s.(unigram) + s.(fwprob5surp), ShiftedGammaShapeGT1(ran=T)) | subject)

