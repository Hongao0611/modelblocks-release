achievement unlocked: make the R-GCN code run without failure from beginning to end

ten.cuegraphs is the head of the wsj and I can confirm that the RGCN code runs and completes some kind of output with it. 

I have a conda environment in which this stuff works: source activate rgcn

the .dict and train.txt files are created by ../scripts/cue2vec_preprocessor.py or something like that
	there are things that can make it run forever, probably cycles in the cuegraph
	that's going to be a very unfortunate limitation

the .pt files are created next by ../scripts/cuegraphs2vectors.py or whatever it's called
	minimum mandatory arguments: 
	--dataset= a directory name
	--rel-type= either vector or matrix
	--loss= either bcc or cos

We have an unheralded infinite loop (in utils.py) if the --graph-batch-size parameter (default 1000?)
is so large that the trainer cannot sample that many edges out of the graph
	(larger than train.txt is long, which is 2x edges because it has forward and reverse)

working for ten.cuegraphs: --rel-type=vector --loss=cos --graph-batch-size=10
	I didn't say it was useful, just that it works

torch.save(obj, "path") is used to record the nodes and rels in .pt files
torch.load("path") will pull them back as torch.Tensor objects
the Tensor for nodes has same length as entities.dict and I presume is 1-to-1
ditto for rels and relations.dict

------------------------------

now, how do we use them to do link prediction? check the training code for hints

it would be good if possible to check the edge count against that param before the loop
then let's look into improving the preprocessor

---------------------

Confirmed: the edge count is as simple as the number of lines in train.txt
also available as n_triplets RIGHT IN the edge sampler 
and --graph-batch-size can be that big but no bigger, or boom

Disturbing question: Why DOESN'T it infinite-loop on smaller batch sizes?
	As written, it appears to be selecting edge adjacent to random node
	Surely some of those nodes will run out of unpicked edges before the graph does
	I'd better read the paper for the intended behavior. BRB.

---------------

Let's de-suck the preprocessor.
	infinite loops

-------------------

the first 100ish sentences of wikisem have been de-cycled, can maybe run on...casp.discgraphs

make of .cuegraphs is currently broken
cue2vec preprocessor might be able to run on .discgraphs, try it

unclear if preproc is looping infinitely on de-cycled cuegraphs, or looping infinitely on cycles, or just taking a really long time

